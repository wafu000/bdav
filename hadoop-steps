check Java:
java -version
*******************************
download and extract hadoop
**********************************
install openssh
*********************************
passwordless ssh:

ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys
***********************************
.bashrc

export JAVA_HOME=/home/sohan/jdk1.8.0_301
export HADOOP_HOME=/home/sohan/hadoop-3.2.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME

source ~/.bashrc
************************************
Add into file $HADOOP_HOME/etc/hadoop/hadoop-env.sh:

export JAVA_HOME=/home/sohan/jdk1.8.0_301
************************************
Add into file core-site.xml:

<configuration>
<property>
<name>hadoop.tmp.dir</name>
<value>/home/sohan/hadoop-3.2.2/tmp</value>
<description>A base for other temporary directories.</description>
</property>
<property>
<name>fs.defaultFS</name>
<value>hdfs://localhost:9000</value>
<description></description>
</property>
</configuration>
************************************
Add into file $HADOOP_HOME/etc/hadoop/mapred-site.xml :

<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
<property>
<name>mapreduce.application.classpath</name>
<value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
</property>
<property>
  <name>yarn.app.mapreduce.am.env</name>
  <value>HADOOP_MAPRED_HOME=/home/sohan/hadoop-3.2.2</value>
</property>
<property>
  <name>mapreduce.map.env</name>
  <value>HADOOP_MAPRED_HOME=/home/sohan/hadoop-3.2.2</value>
</property>
<property>
  <name>mapreduce.reduce.env</name>
  <value>HADOOP_MAPRED_HOME=/home/sohan/hadoop-3.2.2</value>
</property>
</configuration>
**************************************
Add into file $HADOOP_HOME/etc/hadoop/hdfs-site.xml :

<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/usr/local/hadoop_store/hdfs/namenode</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/usr/local/hadoop_store/hdfs/datanode</value>
</property>
</configuration>
***************************************
Add into file $HADOOP_HOME/etc/hadoop/yarn-site.xml:

<configuration>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.env-whitelist</name>
<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
</property>
</configuration>
*****************************************
Execute below commands in Linux terminal 1 by 1:

sudo mkdir -p /home/sohan/hadoop-3.2.2/tmp
sudo mkdir -p /usr/local/hadoop_store/hdfs/namenode
sudo mkdir -p /usr/local/hadoop_store/hdfs/datanode

sudo chmod -R 777 /home/sohan/hadoop-3.2.2/tmp
sudo chmod -R 777 /usr/local/hadoop_store/hdfs/namenode
sudo chmod -R 777 /usr/local/hadoop_store/hdfs/datanode
****************************************
format the hdfs:

hdfs namenode -format

This step has to complete successfully. You can ignore the Warnings/SHUTDOWN MSG if any
*****************************************
Start-hadoop:

start-dfs.sh
start-yarn.sh
***********************************
Check below UIs in the Browser(firefox/chrome) of linux machine:

http://localhost:9870 - Namenode UI
http://localhost:8088 - Resource Manager UI
